
import numpy as np

class BayesianRiskModel:
    def __init__(self):
        # DÃ©finition des priors (lois a priori) pour chaque facteur
        # Ces valeurs sont des hypothÃ¨ses raisonnables basÃ©es sur des recherches gÃ©nÃ©rales
        # Pour simplifier, nous utilisons des distributions Beta pour les probabilitÃ©s
        # alpha et beta sont les paramÃ¨tres de la distribution Beta
        # alpha = nombre de succÃ¨s + 1, beta = nombre d'Ã©checs + 1
        # Un alpha plus Ã©levÃ© et un beta plus faible indiquent une probabilitÃ© a priori plus Ã©levÃ©e de succÃ¨s

        self.priors = {
            'concentration': {'alpha': 2, 'beta': 8},  # Faible concentration (Gini faible, top holders faible) est favorable
            'retention_utilisateurs': {'alpha': 8, 'beta': 2}, # Forte rÃ©tention est favorable
            'activite_dev': {'alpha': 7, 'beta': 3},     # Forte activitÃ© dev est favorable
            'distribution_token': {'alpha': 3, 'beta': 7}, # Distribution Ã©quitable, peu de vesting team/VC est favorable
            'gouvernance': {'alpha': 6, 'beta': 4},      # Bonne gouvernance, participation Ã©levÃ©e est favorable
            'securite': {'alpha': 9, 'beta': 1},         # Bonne sÃ©curitÃ© (audits, pas de vulnÃ©rabilitÃ©s) est favorable
            'liquidity_depth': {'alpha': 7, 'beta': 3},  # Forte liquiditÃ© est favorable
            'activite_ecosysteme': {'alpha': 8, 'beta': 2} # Forte activitÃ© Ã©cosystÃ©mique est favorable
        }

    def calculate_posterior(self, prior_alpha, prior_beta, observed_successes, observed_failures):
        # Calcul de la probabilitÃ© postÃ©rieure en utilisant la formule de Bayes avec des distributions Beta
        # P(H|D) = P(D|H) * P(H) / P(D)
        # Pour une distribution Beta, la mise Ã  jour est simple:
        # alpha_posterior = alpha_prior + observed_successes
        # beta_posterior = beta_prior + observed_failures
        
        posterior_alpha = prior_alpha + observed_successes
        posterior_beta = prior_beta + observed_failures
        
        # La moyenne de la distribution Beta est alpha / (alpha + beta)
        return posterior_alpha / (posterior_alpha + posterior_beta)

    def estimate_probabilities(self, observations):
        # observations est un dictionnaire des facteurs avec une valeur entre 0 et 1
        # oÃ¹ 1 est trÃ¨s favorable et 0 est trÃ¨s dÃ©favorable
        # Nous devons convertir ces observations en 'succÃ¨s' et 'Ã©checs' pour la distribution Beta

        # Pour chaque facteur, nous allons estimer une probabilitÃ© de 'succÃ¨s' (favorable) ou 'Ã©chec' (dÃ©favorable)
        # et mettre Ã  jour les priors en consÃ©quence.
        # Par exemple, si 'concentration' est 0.2 (dÃ©favorable), cela signifie plus d'Ã©checs que de succÃ¨s.
        # Si 'concentration' est 0.8 (favorable), cela signifie plus de succÃ¨s que d'Ã©checs.

        # Pour simplifier, nous allons considÃ©rer que chaque observation est basÃ©e sur 10 'essais' virtuels
        # oÃ¹ l'observation est la proportion de 'succÃ¨s'.
        
        total_posterior_success_prob = 0
        total_factors = len(self.priors)

        for factor, prior_params in self.priors.items():
            if factor in observations:
                observed_value = observations[factor]
                
                # Convertir l'observation en succÃ¨s/Ã©checs virtuels
                # Par exemple, si observed_value = 0.8, et 10 essais virtuels:
                # observed_successes = 8, observed_failures = 2
                virtual_trials = 10 # Nombre d'essais virtuels pour l'observation
                observed_successes = observed_value * virtual_trials
                observed_failures = (1 - observed_value) * virtual_trials
                
                # Calculer la probabilitÃ© postÃ©rieure pour ce facteur
                posterior_prob = self.calculate_posterior(
                    prior_params['alpha'], 
                    prior_params['beta'], 
                    observed_successes, 
                    observed_failures
                )
                total_posterior_success_prob += posterior_prob
            else:
                # Si un facteur n'est pas observÃ©, utiliser la moyenne du prior comme probabilitÃ©
                total_posterior_success_prob += prior_params['alpha'] / (prior_params['alpha'] + prior_params['beta'])

        # Calculer la probabilitÃ© moyenne de succÃ¨s pour le projet
        P_success = total_posterior_success_prob / total_factors

        # P.R.E. (ProbabilitÃ© de Risque dâ€™Ã‰chec) = 1 - P_success
        P_R_E = 1 - P_success
        # P.A.D. (ProbabilitÃ© dâ€™Accumulation Durable) = P_success
        P_A_D = P_success

        return P_R_E, P_A_D

    def interpret_results(self, P_R_E, P_A_D, gini_index=None):
        if P_R_E > 0.6:
            return "ðŸ”´ Ã€ Ã©viter"
        elif P_A_D > 0.5 and P_R_E < 0.5:
            # Ajout de la condition Gini < 0.3 pour Favorable
            if P_A_D > 0.65 and gini_index is not None and gini_index < 0.3:
                return "ðŸŸ¢ Favorable"
            else:
                return "ðŸŸ¡ RisquÃ© mais prometteur"
        else:
            return "ðŸŸ¡ RisquÃ© mais prometteur" # Cas par dÃ©faut si aucune des conditions ci-dessus n'est remplie

    def calculate_score(self, P_A_D):
        # Score synthÃ©tique [0-100] basÃ© sur P.A.D.
        return round(P_A_D * 100)

# Exemple d'utilisation (pour les tests)
if __name__ == "__main__":
    model = BayesianRiskModel()

    # Exemple d'observations pour un projet hypothÃ©tique
    # Ces valeurs seraient obtenues Ã  partir des donnÃ©es on-chain rÃ©elles
    observations_exemple = {
        'concentration': 0.3, # Gini index Ã©levÃ©, top holders Ã©levÃ©s (dÃ©favorable)
        'retention_utilisateurs': 0.7, # Bonne rÃ©tention
        'activite_dev': 0.8,     # Forte activitÃ© dev
        'distribution_token': 0.6, # Distribution correcte
        'gouvernance': 0.7,      # Bonne gouvernance
        'securite': 0.9,         # TrÃ¨s bonne sÃ©curitÃ©
        'liquidity_depth': 0.8,  # Forte liquiditÃ©
        'activite_ecosysteme': 0.7 # Forte activitÃ© Ã©cosystÃ©mique
    }

    P_R_E, P_A_D = model.estimate_probabilities(observations_exemple)
    print(f"P.R.E. (ProbabilitÃ© de Risque dâ€™Ã‰chec): {P_R_E:.2f}")
    print(f"P.A.D. (ProbabilitÃ© dâ€™Accumulation Durable): {P_A_D:.2f}")

    # Pour l'interprÃ©tation, nous avons besoin du Gini index si la condition Favorable est potentiellement remplie
    gini_example = 0.25 # Exemple de Gini index
    interpretation = model.interpret_results(P_R_E, P_A_D, gini_example)
    print(f"InterprÃ©tation: {interpretation}")

    score = model.calculate_score(P_A_D)
    print(f"Score synthÃ©tique: {score}/100")

    # Exemple pour un projet avec des observations dÃ©favorables
    observations_defavorables = {
        'concentration': 0.8, # Gini index faible, top holders faibles (favorable)
        'retention_utilisateurs': 0.2, # Faible rÃ©tention
        'activite_dev': 0.3,     # Faible activitÃ© dev
        'distribution_token': 0.2, # Mauvaise distribution
        'gouvernance': 0.3,      # Mauvaise gouvernance
        'securite': 0.5,         # SÃ©curitÃ© moyenne
        'liquidity_depth': 0.4,  # Faible liquiditÃ©
        'activite_ecosysteme': 0.3 # Faible activitÃ© Ã©cosystÃ©mique
    }

    P_R_E_def, P_A_D_def = model.estimate_probabilities(observations_defavorables)
    print(f"\nProjet dÃ©favorable - P.R.E.: {P_R_E_def:.2f}")
    print(f"Projet dÃ©favorable - P.A.D.: {P_A_D_def:.2f}")
    interpretation_def = model.interpret_results(P_R_E_def, P_A_D_def)
    print(f"InterprÃ©tation: {interpretation_def}")
    score_def = model.calculate_score(P_A_D_def)
    print(f"Score synthÃ©tique: {score_def}/100")

    # Exemple pour un projet trÃ¨s favorable
    observations_tres_favorable = {
        'concentration': 0.1, # TrÃ¨s faible concentration (trÃ¨s favorable)
        'retention_utilisateurs': 0.9, # TrÃ¨s bonne rÃ©tention
        'activite_dev': 0.9,     # TrÃ¨s forte activitÃ© dev
        'distribution_token': 0.9, # TrÃ¨s bonne distribution
        'gouvernance': 0.9,      # TrÃ¨s bonne gouvernance
        'securite': 0.95,         # Excellente sÃ©curitÃ©
        'liquidity_depth': 0.9,  # TrÃ¨s forte liquiditÃ©
        'activite_ecosysteme': 0.9 # TrÃ¨s forte activitÃ© Ã©cosystÃ©mique
    }

    P_R_E_tres_fav, P_A_D_tres_fav = model.estimate_probabilities(observations_tres_favorable)
    print(f"\nProjet trÃ¨s favorable - P.R.E.: {P_R_E_tres_fav:.2f}")
    print(f"Projet trÃ¨s favorable - P.A.D.: {P_A_D_tres_fav:.2f}")
    gini_tres_fav = 0.15 # TrÃ¨s faible Gini index
    interpretation_tres_fav = model.interpret_results(P_R_E_tres_fav, P_A_D_tres_fav, gini_tres_fav)
    print(f"InterprÃ©tation: {interpretation_tres_fav}")
    score_tres_fav = model.calculate_score(P_A_D_tres_fav)
    print(f"Score synthÃ©tique: {score_tres_fav}/100")


